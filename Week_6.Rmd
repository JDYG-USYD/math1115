---
title: "Linear Models"
output: rmdformats::robobook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(ggplot2)
```

# Summary 

- Bivariate data: data that involves two variables. 

- Scatter plot: a graphical summary of two variables on the same 2D plane, resulting in a cloud of points. 

- Linear association: Between two variables, measure how tightly the points cluster around a line **where if there is a strong association**, the cloud of the points will be tightly clustered around a line (i.e. one variable may be used to predict the other)

- Correlation coefficient (*r*): measures the clustering around the line and indicates both the sign and strength of the linear association.

    - Lies between -1 and +1 where if *r* = +/-1, there is perfect correlation (i.e. all the points lie on the line). 
    
    - When *r* = 0, there is no correlation. 
    
    - *r* is a pure number (no units)
    
    - A positive *r* means a positive correlation, and a negative *r* a negative. 
    
- Regression line uses 5 numerical summaries:

  - Mean of *x*
  
  - Mean of *y*
  
  - SD of *x*
  
  - SD of *y*
  
  - *r*

At the end of this Lab, you should be able to examine the relationships between variables using *correlation* and *visualization*, and justify whether regression is an appropriate model for the data (L04)

#  Statistical Thinking 

Let's randomize some data to generate an x-y relationship.

```{r}
set.seed(123) # Making sure random happens in a same boat.
df <- tibble(x = rnorm(100, 0, 3), y = rnorm(100, 0, 3))

ggplot(df, aes(x, y)) +
  geom_point(size = 2, colour = "cornflowerblue") +
  theme_bw()
```

5 elements:
  
```{r}
x_avg <- sum(df$x) / 100
x_mean <- mean(df$x)
x_sd <- sd(df$x)
y_avg <- sum(df$y) / 100
y_mean <- mean(df$y)
y_sd <- sd(df$y)

knitr::kable(tibble(x_avg, x_mean, x_sd, y_avg, y_mean, y_sd, cor = cor(df$x,df$y)), align = "cc")
```

2. Given these options: -1, nearly -1, somewhat negative, 0, somewhat positive, nearly 1 and 1; what is the correlation between (with a short explanation):

    a. A person's age and their year of birth? Should be 1 
    
    b. The price of a car and time? Should be nearly -1

3. Given that the *family's income = husband's income + wife's income*, and using the same options as in Q2; what is the correlation between (with a short explanation):

    a. The wife's income and the family income? Should be nearly 1
    
    b. The wife's income and the husband's income? Should be 0
    
4. True or False: if $r = 0.90$, then 90% of the points are highly correlated.

5. Given the small data set below;  $r \approx\ 0.76$

    a. If you switch the two columns, does this change *r*? 

    b. If you add 3 to each value of *y*, does this change *r*?

    c. Justify in R. 

```{r}
data.frame(xvar = c(1:5), yvar = c(2, 3, 1, 5, 6))
```

# Demo

## Olympic 100m sprint 

### Domain knowledge

The 100 m men sprint is considered one of the most prestigious events at each Olympics.
Who holds the current world record time for men, and what was his time?
[Olympic times](https://www.olympic.org/athletics/100m-men).

Let's dive into our own data set.

```{r, message=FALSE}
olympics <- read_csv("data/Olympics100m.csv")
glimpse(olympics) # check structure
```

While it is an *optional* step, cleaning the data can lead to faster processing times (and less confusion about variable names). What "problems" can you observe in the `olympics` data?

```{r}
# Cleaning is important
olym <- 
  olympics %>%
  rename(name = 2) %>% # rename a column
  select(-6, -7) %>%   # discard columns with `-` - useless cols
  janitor::clean_names()  # make col names lower-cased and regulated

glimpse(olym) # what has changed?
```

Let's explore the data with `plot()`.

```{r}
plot(olym)
```

What patterns can we see? 

- There are factors

- Countries biased

- Year and time

How many gold medal records are won each year?

```{r}
olym %>%
  pull(year) %>% # Get attribute and all its appearances
  table()  # why do some years have 2 counts while others have only 1? 
```

From the output above we can observe that before 1928, only one winning time was recorded instead of two. What is causing this pattern?

```{r}
olym %>%
  group_by(gender) %>%
  summarise(total = sum(n())) %>% # count rows per group
  knitr::kable(caption = "Table 1: Total world records from 1896 - 2016.", align = "cc")
```

Note that up to this point, we are still exploring the data for insights.

### Univariate exploration

Please look through this section at your own time as we will only briefly go through the steps.

> When was the men's slowest race time? How does it compare to the women's fastest time?

```{r}

olym %>%
  filter(gender == "male") %>%
  select(time) %>%
  max()

olym %>%
  filter(gender == "female") %>%
  select(time) %>%
  min()

olym %>%
  group_by(gender) %>%
  summarise(max = max(time),
            min = min(time)) %>% 
  gt::gt()
```

> Which country has the most winning records?

To answer this question, we need to sort by country and count the rows.

```{r}
most_gold <- 
  olym %>%
  group_by(country) %>%
  tally() %>%
  arrange(desc(n)) 

most_gold
```

The output shows that the most winning records go to `r most_gold[1, 1]`.

Plotting the data would probably be nicer!

```{r}
most_gold %>%
  # slice(1:6) %>%
  ggplot(aes(n, reorder(country, n))) +
  geom_bar(stat = "identity", colour = "white", fill = "cornflowerblue") +
  theme_bw() +
  xlab("Gold medal count") +
  ylab("Country (abbreviated)") +
  ggtitle("Which country has the most gold medals?")
```

We might group all the countries having 1 gold medal, but plz don't remove it.

### Bivariate relationships

> What pattern can we observe when we plot men's winning time (`time`) with `year`?dw

Eventually, we want to move beyond simple summary statistics and start to compare between variables.

- Construct a linear model between winning time and year for men. Using the model, predict the winning time for the 2021 Olympics (delayed due to COVID-19). Is this reliable?

- Your research question concerning a linear model should involve 2 quantitative/continuous variables. *Does the data fit the requirement?*

We will:

1. Generate the scatter plot and check correlation;

2. Fit a linear model on the data;

3. Check assumptions;

4. Interpret the results;

5. Update the plot with the model; 

6. Make a prediction (optional).

### **Step 1**: generate the scatter plot and check correlation

```{r}
male_time <- 
  olym %>%
  filter(gender == "male") %>%
  select(year, time) 

p1 <- 
  ggplot(male_time, aes(year, time)) +
  geom_point() +
  theme_bw() +
  xlab("Year") +
  ylab("Time (s)") +
  ggtitle("Relationship between year (x) and winning time (y)\nin the Olympic 100 m sprint, 1896-2016") # note how we can wrap the text using `\n`

p1

# check correlation
cor(male_time)
```

### **Step 2**: fit a linear model

Linear models are constructed using the `lm()` function. Note that we use the formula `y ~ x` to express a relationship between `x` and `y`.

What is the formula?

- Formula (bi-variate relationship)

- y ~ x (tilde)

- y is a function of x (f(x)), y is the predicting value

- y can be influenced by predictor x

- For any relationship, define such function y ~ x

```{r}
# lm(y ~ x, data)
# Also t.test, chisq... and tidymodules!
fit <- lm(time ~ year, male_time)
fit
```

### **Step 3**: check assumptions

Before proceeding, it is important to check if the data meets the assumptions of a linear model. These following assumptions apply:

- independence of x and y

- data meets assumption of normality

- data meets assumption of homogeneity of variances (equal variances)

  - Making sure that distance between entries to the lm line is somehow equal distanced.

Warning: the model produces results even if assumptions are not met!

We can simply `plot()` the model object to check these assumptions from the residuals produced by the model.

- First plot: check for linearity and equal variances

- Second plot: check for normality

- Third plot: check for equal variances

- Fourth plot: check for important outlines

The data meets both the assumptions of normality and equal variances.

```{r}
plot(fit)
```

### **Step 4**: interpret the results

Using the `summary()` function allows us to check the model output including R^2^ and p-value.

```{r}
summary(fit)
```

Note: if the model does not meet the assumptions, we should NOT proceed to this step.

The results show that there is a significant linear relationship between sprint time and year (R^2^ = 0.8, p < 0.01).

### **Step 5**: Update the plot

```{r}
p1 +
  geom_smooth(method = "lm") +
  geom_line(aes(y = predict(fit))) # Own line in own made prediction with own function
```


### **Step 6**: predict (optional)

Should we use this relationship to make a prediction for 2021? What about 2024?

```{r}
predict(fit, newdata = data.frame(year = c(2021, 2024)))
```

It is often dangerous to predict outside a model, especially in a time series dataset!

# Explore: Air quality in Sydney 

## Domain knowledge

- The Sydney Air Quality dataset comes from [Environment NSW](http://www.environment.nsw.gov.au/AQMS/search.htm).

```{r message=FALSE}
air <- read_csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/current/data/AQI_July2015.csv")

glimpse(air) 
```

- According to this [AQI Info](http://www.health.nsw.gov.au/environment/air/Pages/aqi.aspx), what is the AQI? What does it measure? Why is it important?
- Check out this scary [visualisation](http://aqicn.org/map/). What stands out?   

## Univariate exploration

Investigate your own questions, for example:

- What day had the worst air quality? `
- Which region (CE or NW) has overall better air quality?

## Bivariate relationship

Investigate your own questions, for example:

- Produce a scatter plot (in `ggplot2`) and calculate the correlation. What does this tell you?
- Could you predict the air quality in one region from the other?

# Past Data Stories {-}

For each of the previous data stories, propose a research question involving linear regression (bivariate).